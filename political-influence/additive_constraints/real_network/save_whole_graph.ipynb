{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "DATASET = 'uselections'  # other datasets: \"brexit\", \"abortion\"\n",
    "DATASETS_PATH = path.join(path.pardir, \"datasets\", \"balanced_exposure\")\n",
    "DATASET_PATH = path.join(DATASETS_PATH, DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load probabilities\n",
    "PROBS_PATH = path.join(DATASET_PATH, f\"{DATASET}_network_heterogeneous.txt\")\n",
    "df = pd.read_csv(PROBS_PATH, sep='\\t', names=['User', 'Follower', 'Pa', 'Pb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 99)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load seeds\n",
    "A = [l.strip() for l in open(path.join(DATASET_PATH, \"side1_seeds.txt\")).readlines()]  # A = pro Hillary\n",
    "B = [l.strip() for l in open(path.join(DATASET_PATH, \"side2_seeds.txt\")).readlines()]  # B = pro Trump\n",
    "len(A), len(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label group attribute for user and follower\n",
    "A1, B1 = df.User.isin(A), df.User.isin(B)\n",
    "df['Group1'] = np.where(~A1 & ~B1, 'NA', np.where(A1, 'A', 'B')) \n",
    "\n",
    "A2, B2 = df.Follower.isin(A), df.Follower.isin(B)\n",
    "df['Group2'] = np.where(~A2 & ~B2, 'NA', np.where(A2, 'A', 'B')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get node information (label and group)\n",
    "nodes = (pd.concat([df[['User', 'Group1']].rename(columns={'User': 'Label',\n",
    "                                                           'Group1': 'Group'}),\n",
    "                    df[['Follower', 'Group2']].rename(columns={'Follower': 'Label', \n",
    "                                                               'Group2': 'Group'})])\n",
    "           .drop_duplicates()\n",
    "           .reset_index(drop=True)\n",
    "           .reset_index()\n",
    "           .rename(columns={'index': 'Id'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print to file\n",
    "nodes.to_csv('all_nodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edge information: follower -> user\n",
    "gephi_format = {'User': 'Target', 'Follower': 'Source'}\n",
    "edges = (df[['User', 'Follower']].rename(columns=gephi_format)\n",
    "                                 .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {v: i for i, v in enumerate(nodes[['Id', 'Label']].set_index('Id').Label.to_dict().values())}\n",
    "edges['Target'] = edges['Target'].map(replace_dict)\n",
    "edges['Source'] = edges['Source'].map(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edges = pd.read_csv('all_edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "edges.to_csv('all_edges.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do all the nodes appear in an edge?\n",
    "unique_nodes = set(nodes.index.tolist())\n",
    "nodes_in_edges = set(np.unique(edges.values.reshape(-1)))\n",
    "\n",
    "assert len(unique_nodes.difference(nodes_in_edges)) == 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
